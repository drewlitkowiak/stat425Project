---
title: 'STAT 425: Final Project'
author: "Spring 2019, Drew, Jason Luo, Kris Kresto"
date: 'Due: Tuesday, December 17th by 11:59 PM CT'
output:
  html_document:
    theme: readable
    toc: yes
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```




```{r}
# loading library, setting seed 
library(dplyr)
```


```{r}
train_csv = read.csv('csv/train.csv')
key_csv = read.csv("csv/key.csv")
weather_csv_new = read.csv("csv/weather.csv")
test_csv = read.csv("csv/test.csv")
```

```{r}
weather_csv = weather_csv_new

double_converts = c("sealevel", "stnpressure", "preciptotal", "snowfall", "resultspeed", "avgspeed")
for (name in double_converts) {
  weather_csv[, name] = as.double(as.character(weather_csv[, name]))
}

int_converts = c("tmax", "tmin", "tavg", "dewpoint", "depart", "wetbulb", "heat", "cool")
for (name in int_converts) {
  weather_csv[, name] = as.double(as.character(weather_csv[, name]))
}

split_date_hyphen = strsplit(as.character(weather_csv$date), "-")

weather_csv$year = ""
weather_csv$month = ""
weather_csv$day = ""

for (i in 1:nrow(weather_csv)) {
  weather_csv[i, "year"] = split_date_hyphen[[i]][1]
  weather_csv[i, "month"] = split_date_hyphen[[i]][2]
  weather_csv[i, "day"] = split_date_hyphen[[i]][3]
}

weather_csv$year = as.factor(weather_csv$year)
weather_csv$month = as.factor(weather_csv$month)
weather_csv$day = as.factor(weather_csv$day)

weather_csv$heat_cool = weather_csv$heat - weather_csv$cool

weather_csv$resultdir = as.double(as.character(weather_csv$resultdir))
deg_to_rad_ratio = pi / 18
weather_csv$resultdir = sin(weather_csv$resultdir * deg_to_rad_ratio)

#weather_csv
#TODO perform box-cox on variance in sealevel
```


```{r}
# Impute data for sealevel
library(dplyr)
library(imputeTS)

weather_csv = weather_csv %>%
     group_by(station_nbr) %>%
     mutate(sealevel = ifelse(station_nbr == 8, sealevel, na_interpolation(sealevel))) %>%
    ungroup(station_nbr)

combined_sealevels <- vector("list", 19)
iter_seq = c(1:4, 6:20)

for (i in iter_seq) {
  var_name = paste0("slevel", i)
  assign(var_name, weather_csv[weather_csv$station_nbr == i, "sealevel"])
  combined_sealevels[[i]] = get(var_name)
  rm(list=c(var_name))
}

combined_sealevels = as.data.frame( matrix(unlist(combined_sealevels), ncol = 19) )
means = rowMeans(combined_sealevels[, -7])

weather_csv = weather_csv %>%
  group_by(station_nbr) %>%
  mutate(sealevel = ifelse(station_nbr == 8, means, sealevel)) %>%
  ungroup(station_nbr)
```

```{r}
#impute snowfall
library(sjmisc)

is_snowing = function(string) {
  return(str_contains(string, "SN"))
}
is_snowing.vec = Vectorize(is_snowing, vectorize.args = c("string"))

weather_csv = weather_csv %>%
  mutate(does_snow = is_snowing.vec(as.character(codesum))) %>%
  mutate(snowfall = ifelse(is.na(snowfall) & !does_snow, 0, snowfall))


weather_csv = weather_csv %>%
  group_by(month, station_nbr, codesum) %>%
  mutate(snowfall = ifelse(is.na(snowfall), mean(snowfall, na.rm = TRUE), snowfall)) %>%
  ungroup(codesum) %>%
  mutate(snowfall = ifelse(is.na(snowfall), mean(snowfall, na.rm = TRUE), snowfall)) %>%
  ungroup(station_nbr) %>%
  mutate(snowfall = ifelse(is.na(snowfall), mean(snowfall, na.rm = TRUE), snowfall)) %>%
  ungroup(month) %>%
  group_by(station_nbr) %>%
  mutate(snowfall = na_interpolation(snowfall))
```

```{r}
key_and_train = key_and_train %>%
  group_by(store_nbr, item_nbr) %>%
  filter(sum(units) != 0) %>%
  ungroup(store_nbr, item_nbr)
```


```{r}
#weather_csv$diff_sealevel_from_mean = 
library(dplyr)

weather_csv %>%
  filter(!is.na(sealevel)) %>%
  group_by(station_nbr) %>%
  mutate(sealevel_diff = sealevel - mean(sealevel))

names = colnames(weather_csv)
for (name in names) {
  if(sum(is.na(weather_csv[,name])) > 0) {
      print(paste0("There are Na(s) in ", name))
      
      weather_csv[is.na(weather_csv[,name]), name] = median(weather_csv[,name], na.rm = TRUE)
      print("Mean values imputed")
  }
}
  
# plot_points = function(vec) {
#   print(vec)
#   qqnorm(vec)
#   qqline(vec, col = 2)
# }
# 
# weather_csv %>%
#   filter(!is.na(preciptotal)) %>%
#   group_by(station_nbr) %>%
#   do(plot_points(.$preciptotal)) %>%
#   ungroup()
weather_csv
  
```





# Section 1: Introduction 



# Section 2: Exploratory Data Analysis 

```{r}


dropped_columns = c("sunrise", "sunset", "depart", "heat", "cool")
weather_csv = weather_csv[ , !(names(weather_csv) %in% dropped_columns)]

dropped_columns = c("date", dropped_columns)
full_set = full_set[ , !(names(full_set) %in% dropped_columns)]

# graphical analysis 
# Adding time variables 
```

```{r}
bad_model = readRDS("/Volumes/SMALLDRIVE/lm_model.rds")
```


# Section 3: Linear Regression 

```{r}
key_and_train = dplyr::inner_join(x = train_csv, y = key_csv, by = "store_nbr")
full_set = dplyr::inner_join(key_and_train, weather_csv, by=c("date", "station_nbr"))

dropped_columns = c("date")
full_set = full_set[ , !(names(full_set) %in% dropped_columns)]

saveRDS(full_set, "full_set.rds")

rm(list = ls())
```

```{r}
full_set = readRDS("full_set.rds")
full_set
```


```{r}
library(MASS)

bad_model = lm(units ~ ., data = full_set)

empty_model = lm(units ~ 1, data = full_set)

forward_model = step(empty_model, scope = list(upper = bad_model, lower = empty_model), direction = "forward")
```

```{r}
library(glmnet)

#for testing purposes
#full_set = full_set[1:2000, ]
memory.limit(128 * 1024)

response_vec = full_set$units
full_set = full_set[, !(colnames(full_set) == "units")]
full_set = model.matrix(~ ., data = full_set)
full_set





for(i in seq(0, 1, by = 0.1)) {
  print(paste0("Running glmnet with alpha = ", i, "..."))
  glmnet(full_set, response_vec, alpha = i)
  model_name = paste0("glm_model_", i*10)
  assign(model_name, glmnet(full_set, response_vec, alpha = i))
  file_name = paste0(model_name, ".rds")
  print(paste("Model generated. Saving to file as", file_name))
  saveRDS(get(model_name), file = file_name)
  rm(list = c(model_name))
}



```

# Section 4: Improvements

